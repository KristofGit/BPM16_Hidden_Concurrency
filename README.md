Hidden Concurrency Testing
=============

Prototypical implementation for the submission: Kristof BÃ¶hmer and Stefanie Rinderle-Ma: A Testing Approach for Hidden Concurrencies based on Process Execution Logs.

The prototypical implementation of the presented execution log analyzation approach was applied during the evaluation of the submission. It analyzes process execution logs, identifies units (activities) that likely observe concurrency faults and selects appropriate test cases which enable to verify the identified units for concurrency faults. Moreover it contains additional algorithms which were only utilized during the evaluation (e.g., a random prioritization approach (utilized as a baseline for existing work and the proposed approach) or the calculation of the Average Percentage of Faults Detected (APFD) metric which enables to evaluate the efficiency of the presented concurrency testing prioritization approach). 

XESParser
---------

The implementation was split into four projects. First, the **XESParser** project which enables to read and prepare XES logs for the following analysis steps. Hereby, it especially focuses on real life  BPIC 2015 and the artificial TeleClaim logs. Note, that each log uses different parameter names and approaches to encode the start and end times of the stored events. Those events are crucial for the hidden concurrency analysis. Hence, by setting the LogType enumeration to BPIC or TeleClaim it can be configured which type of log is currently processed. Note, that the XESParser project also contains the MainConfiguration class which holds all important settings (e.g. the log type enumeration setting) used by the prototype (e.g., where to search for the yet to be analyzed logfiles, where to store the results, etc.).

TestGroupSelection
------------------

Secondly,  the data extracted by the XESParser project is processed by the **TestGroupSelection** project. This project processes units and events which were specified at the parsed process execution logs, determines which units are executed in an overlapping fashion and which specific executions are overlapping and how. Subsequently, the Hidden Concurrency (HC) risk is calculated that indicates the likelihood that two units are executed concurrently and, therefore, observe concurrency faults. The HC risk is subsequently utilized to create unit groups (for each unit an individual unit group is constructed) which are then transformed into test groups which verify the identified concurrent executions. The necessary test cases are automatically generated based on the analyzed XES process execution logs.

TestGroupPrioritization
-----------------------

Thirdly, the **TestGroupPrioritization** project which contains all the necessary code to prioritize the generated test groups.  Especially, it contains the definition and calculation methods of the primary and secondary prioritization factors/metrics. The required information to calculate these metrics are provided directly from the XESParser project (i.e., extracted from the XES log files) or automatically generated by the  TestGroupSelection project (e.g., the hidden concurrency risk).

Evaluation
----------

Fourthly, the **Evaluation** project. It combines the results of all other projects, for example, to generate test groups and prioritize them. Moreover it contains the necessary code for the evaluation. For example, to calculate the APFD metric to compare the performance of the proposed prioritization approach and existing work.  

